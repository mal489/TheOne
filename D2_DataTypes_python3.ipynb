{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mal489/TheOne/blob/main/D2_DataTypes_python3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgPXqQE3hBla"
      },
      "source": [
        "# INFO 103: Introduction to data science <br> Demo \\#2: Data Types <br> Author: JRW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeMkSvYQhBle"
      },
      "source": [
        "## Data\n",
        "Here's a list of the files that we will be working with in this notebook:\n",
        "\n",
        "* Image: ./Rgb-raster-image_smile.jpg\n",
        "* Text: ./MobyDick.txt\n",
        "* Spreadsheet: ./APPL.csv\n",
        "* html: ./index.html\n",
        "* json: ./youtube.json\n",
        "* xml: ./simple.xml\n",
        "\n",
        "All of the paths start with a './' because they should be in the same directory as this notebook. Also, here are the sources, for reference:\n",
        "\n",
        "* Image: https://en.wikipedia.org/wiki/Raster_graphics\n",
        "* Text: http://www.gutenberg.org/ebooks/2701\n",
        "* Spreadsheet: https://finance.yahoo.com/quote/AAPL/history?p=AAPL\n",
        "* html: http://www.example.com\n",
        "* json: https://www.sitepoint.com/10-example-json-files/\n",
        "* xml: https://www.w3schools.com/xml/xml_examples.asp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9uC9Eq5hBlh"
      },
      "source": [
        "### Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "se3NON01hBli"
      },
      "outputs": [],
      "source": [
        "import numpy as np ## numpy provides a suite of numerical\n",
        "import pandas as pd ## pandas provides nice ordered array (spreadsheet) handling\n",
        "import re ## re provides regular expressions, which help with text\n",
        "import json ## json provides json-format data management\n",
        "import datetime ## datetime interprets dates as numerical quantities\n",
        "from bs4 import BeautifulSoup ## Beautifulsoup parses html, thus, also xml!\n",
        "from IPython.core.display import display ## display allows you to show an image here in the notebook\n",
        "from PIL import Image ## Image allows you to edit image data\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCDIBG2ZhBll"
      },
      "source": [
        "### Spreadsheets\n",
        "I'm pretty basic when it comes to programming, so I usually just use base Python with for loops and regular expressions, but for convenience we'll use pandas, which is great for manipulating spreadsheets as 2-d arrays. Here are what the parameters we use:\n",
        "\n",
        "* filepath_or_buffer: specifies the name of the file\n",
        "* sep: specifies the column separator, here, commmas\n",
        "* header: specifies where the header is, here, row 1\n",
        "* parse_dates: specifies columns to be treated as timestamp objects\n",
        "\n",
        "The resulting pandas object is a \"dataframe\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKgkUGSlhBll"
      },
      "outputs": [],
      "source": [
        "APPL = pd.read_csv(filepath_or_buffer=\"APPL.csv\", sep=\",\", header=0, parse_dates = [0])\n",
        "print(APPL.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-34hsvafhBln"
      },
      "source": [
        "You can access the rows with indices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "M_rHJhgjhBlp"
      },
      "outputs": [],
      "source": [
        "APPL.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZu6ROrHhBlq"
      },
      "source": [
        "and the columns by dictionary keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la1Bjo5ChBlq"
      },
      "outputs": [],
      "source": [
        "print(APPL[\"Date\"][1:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hWwlxqChBlr"
      },
      "source": [
        "Notice the \"Open\" column has floats, while the \"Volume\" column has ints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDhjdO_xhBls"
      },
      "outputs": [],
      "source": [
        "print(type(APPL[\"Open\"][0]))\n",
        "print(type(APPL[\"Volume\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPQsnjMjhBls"
      },
      "outputs": [],
      "source": [
        "APPL[\"Open\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VgdxDWhhBlt"
      },
      "source": [
        "The weird column is Date, which has timestamp objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmoMJHFQhBlt"
      },
      "outputs": [],
      "source": [
        "print(type(APPL[\"Date\"][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWHJZb9ThBlu"
      },
      "source": [
        "You can do the usual math with floats and ints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbHJNPXehBlu"
      },
      "outputs": [],
      "source": [
        "## element-wise subtraction\n",
        "print(APPL[\"Close\"][0] - APPL[\"Open\"][1])\n",
        "print(\"\")\n",
        "## vector-wise subtraction\n",
        "print(APPL[\"Close\"][0:10] - APPL[\"Open\"][0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbSJzo5ihBlv"
      },
      "source": [
        "#### So this is actually a type of timeseries data\n",
        "There are seval numeric data columns, with the dates as the time stamps. If you wanted to plot any of the columns as a timeseries, you would have to be sure the intervals are correct! This can be done automatically, or you can subtract adjacent values to determine intervals. Here's an example subtracting two times to get the difference in days:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs0FmIKMhBlw"
      },
      "outputs": [],
      "source": [
        "print(APPL[\"Date\"][0])\n",
        "print(APPL[\"Date\"][9])\n",
        "print(\"\")\n",
        "print(\"Day 0 and day 9 are actually \"+str((APPL[\"Date\"][0] - APPL[\"Date\"][9]).days)+\" days apart!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuClxAhbhBlx"
      },
      "source": [
        "### Text\n",
        "The file I've got for you here is Hermin Mellville's Moby Dick. This is kind of like the E. coli/lab rat of the text analysis world. I'm going to go super basic and load this text file in one chunk as a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljfCUi-fhBlx"
      },
      "outputs": [],
      "source": [
        "with open(\"MobyDick.txt\", \"r\",encoding='utf-8') as f:\n",
        "    MobyDick = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbee1Yd-hBly"
      },
      "source": [
        "Strings are really just lists, so we can look at the beginning of the text by slicing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIjsyfgEhBl8"
      },
      "outputs": [],
      "source": [
        "MobyDick[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "OFj-lkLAhBl9"
      },
      "outputs": [],
      "source": [
        "print(MobyDick[:10000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKF_SJSRhBl9"
      },
      "source": [
        "#### Text is 'messy'\n",
        "As you can see, there is lots of leader text surrounding the main content, so a main focus with text processing if figuring out how to get what we want. This is where regular expressions come in handy. For the sake of simplicity, let's just grab the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "h8o1SoJrhBl9"
      },
      "outputs": [],
      "source": [
        "index = {}\n",
        "for chapter in re.finditer(\"(CHAPTER\\s+\\d+)\\.\\s+([^\\n\\r]+)\", MobyDick):\n",
        "    ChapNum = chapter.group(1)\n",
        "    if not index.get(ChapNum, False):\n",
        "        index[ChapNum] = {\n",
        "            \"title\": chapter.group(2),\n",
        "            \"text\": \"\"\n",
        "        }\n",
        "print(\"Total chapters: \"+str(len(index.keys())))\n",
        "print(\"\")\n",
        "print(\"This is what we've got for chapter 2:\\n\")\n",
        "print(index[\"CHAPTER 2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeIHDn6phBl-"
      },
      "source": [
        "Grabbing the index was pretty easy, because it was \"semi-structured\", but other forms of text and tasks are really not this nice! For example, now that we have the chapter names, we may want to find the individual chapters and separate them. How could we do this? (Note: The last chapter's text will include any text at the bottom of the document, requiring further preprocessing.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Gr36N_vVhBl-"
      },
      "outputs": [],
      "source": [
        "ByChapter = re.split(\"\\n(CHAPTER \\d+)\\. \", MobyDick)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtAaPu15hBl-"
      },
      "outputs": [],
      "source": [
        "print(ByChapter[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "pFsJulUAhBl_"
      },
      "outputs": [],
      "source": [
        "ByChapter = re.split(\"\\n(CHAPTER \\d+)\\. \", MobyDick)\n",
        "print(\"Total splits: \"+str(len(ByChapter)))\n",
        "TotalChapterTextsFound = 0\n",
        "for i in range(135):\n",
        "    if index.get(ByChapter[2*i+1],False):\n",
        "        TotalChapterTextsFound += 1\n",
        "        index[ByChapter[2*i+1]][\"text\"] = ByChapter[2*(i+1)]\n",
        "#         print(\"Found the text for \"+ByChapter[2*i+1]+\": \"+index[ByChapter[2*i+1]][\"title\"])\n",
        "print(\"\\nFound \"+str(TotalChapterTextsFound)+\" chapter texts in total!\")\n",
        "print(\"Here's what we got for CHAPTER 2: \\n\\n\"+index[\"CHAPTER 2\"][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX8LPUvWhBl_"
      },
      "source": [
        "#### Pre-processing also includes feature selection\n",
        "A primary feature selection task is called \"tokenization.\" A basic way to get tokens is to split by spaces. Counting these \"words\" up creates the \"bag-of-words\" framework for text analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "peafhQvGhBmA"
      },
      "outputs": [],
      "source": [
        "for chapter in index:\n",
        "    tokens = re.split(\" \", index[chapter][\"text\"])\n",
        "    index[chapter][\"counts\"] = {}\n",
        "    for token in tokens:\n",
        "        index[chapter][\"counts\"].setdefault(token, 0)\n",
        "        index[chapter][\"counts\"][token] += 1\n",
        "\n",
        "words = sorted(index[\"CHAPTER 2\"][\"counts\"], key=lambda x: index[\"CHAPTER 2\"][\"counts\"][x], reverse = True)\n",
        "print(\"Here are the top 100 words in CHAPTER 2:\\n\\n\")\n",
        "\n",
        "print(\"\\n\".join([\": \".join(x) for x in zip(map(str,range(1,101)),words[0:100])]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpfX3e7whBmA"
      },
      "source": [
        "### Images\n",
        "Image data is unstructured like text, but presents quite different challenges, as it does not generally represent a language. Let's start by loading our image in and displaying it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "63HSvxjnhBmA"
      },
      "outputs": [],
      "source": [
        "with open('Rgb-raster-image_smile.jpg', 'rb') as inf:\n",
        "    jpgdata = inf.read()\n",
        "image_object = Image.open(BytesIO(jpgdata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJIZ2BYMhBmB"
      },
      "outputs": [],
      "source": [
        "print(image_object)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RdJH5t7hBmB"
      },
      "source": [
        "#### What does image data actually look like?\n",
        "Recall, jpgs are just matricies pixes, which record the intensities of three colors: Red Green and Blue. This is encoded with a python image object as a three dimensional array, i.e., a matrix of triplicate numbers. This image is of size 368 x 400, so we can access pixels in x and y dimensions with indices up to those numbers! (Note: Our image object is only a generator, so the pixels are not actually retrieved unless they are loaded.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sdOJM3WhBmB"
      },
      "outputs": [],
      "source": [
        "px = image_object.load()\n",
        "print(px[0,0])\n",
        "print(px[183,199])\n",
        "print(px[183,100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OClxrWshBmB"
      },
      "source": [
        "To change a pixel to black, all we have to do is zero-out each of the bytes. To change a pixel to white, all we have to do is 255 (recall: there are 256 ways to arrange a single byte). We can do these operations for a bunch of pixes by double looping. (Note: When we alter the pixels, the changes take effect in the image object.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxy64-7lhBmB"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "    for j in range(100):\n",
        "        px[i,j] = (0,0,0)\n",
        "\n",
        "for i in range(200,301):\n",
        "    for j in range(200,301):\n",
        "        px[i,j] = (255,255,255)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E4rBYA4hBmN"
      },
      "outputs": [],
      "source": [
        "for i in range(268,368):\n",
        "    for j in range(300,400):\n",
        "        px[i,j] = (0,0,0)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kiC-XMhBmN"
      },
      "source": [
        "All you have to do is change the RBG intensities to make a variety of colors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqT6WpZihBmO"
      },
      "outputs": [],
      "source": [
        "for i in range(0,368):\n",
        "    for j in range(200,301):\n",
        "        px[i,j] = ((i + j) % 256,i % 256,j % 256)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9NWndxYhBmO"
      },
      "source": [
        "#### What about features here?\n",
        "Features in images take on physical meanings, perhaps related to how we recognize things. So, for faces this might be the distances between eyes. However this means figuring out where the eyes are first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ1hYDKvhBmO"
      },
      "outputs": [],
      "source": [
        "for i in range(166,206):\n",
        "    for j in range(101,141):\n",
        "        px[i,j] = px[i,j] = (0,0,0)\n",
        "\n",
        "for i in range(246,286):\n",
        "    for j in range(101,141):\n",
        "        px[i,j] = px[i,j] = (0,0,0)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5KlEUVXhBmP"
      },
      "source": [
        "So, it looks like the eyes here are about 80 pixels apart. The measurement of this feature might discern our smile from other smiles whose eyes are wider apart. For fun, let's reload the data (since we kind of wrecked it) and give our smile some crazy eyes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTwqFvSchBmP"
      },
      "outputs": [],
      "source": [
        "with open('Rgb-raster-image_smile.jpg', 'rb') as inf:\n",
        "    jpgdata = inf.read()\n",
        "image_object = Image.open(BytesIO(jpgdata))\n",
        "px = image_object.load()\n",
        "\n",
        "for i in range(166,206):\n",
        "    for j in range(101,141):\n",
        "        px[i,j] = ((i * j) % 256,(i + j) % 256,(i - j) % 256)\n",
        "\n",
        "for i in range(246,286):\n",
        "    for j in range(101,141):\n",
        "        px[i,j] = ((i * j) % 256,(i + j) % 256,(i - j) % 256)\n",
        "display(image_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESxzbv6xhBmP"
      },
      "source": [
        "### XML\n",
        "The Extended Markup Language (XML) format is a verbose type of associative data. It uses nested tags: <\\key> ...value... </\\key>. To associate values to keys. Here, we've got a restaurant menu in XML format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG4zX-EohBmP"
      },
      "outputs": [],
      "source": [
        "with open(\"simple.xml\", \"r\") as f:\n",
        "    menu = f.read()\n",
        "print(menu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI6MywV8hBmP"
      },
      "source": [
        "To get the keys and values out of the XML we will need to parse it. We could spend a long time cooking up our own regular expressions for this, but people have already done this quite well, and packed it into the BeautifulSoup module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU-2zSQ3hBmP"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(menu, 'lxml')\n",
        "print(soup.find('food'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4vpgRgxhBmQ"
      },
      "source": [
        "It looks like the schema has each food with a name, price, description and calories. Let's code this into a nice python dict object so we could navigate it more easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zdHosf6hBmQ"
      },
      "outputs": [],
      "source": [
        "ourmenu = {}\n",
        "for food in soup.find_all('food'):\n",
        "    ourmenu[food.find(\"name\").text] = {\n",
        "        \"name\": food.find(\"name\").text,\n",
        "        \"price\": float(re.sub(\"\\$\",\"\",food.find(\"price\").text)),\n",
        "        \"description\": food.find(\"description\").text,\n",
        "        \"calories\": int(food.find(\"calories\").text)\n",
        "    }\n",
        "print(\"Here's what we've got not for Belgian Waffles:\\n\\n\")\n",
        "print(ourmenu[\"Belgian Waffles\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2zEBMsfhBmQ"
      },
      "source": [
        "Since we've cvonverted the prices and calories to floats and ints, respectively, we can now measure some totals for a given mean. For example, let's order a Homestyle Breakfast with a side of Frencch Toast and check the damage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kxb5kVZhBmQ"
      },
      "outputs": [],
      "source": [
        "price = 0.\n",
        "calories = 0\n",
        "for name in [\"Homestyle Breakfast\",\"French Toast\"]:\n",
        "    print(\"Name: \"+name)\n",
        "    print(\"Calories: \"+str(ourmenu[name][\"calories\"]))\n",
        "    print(\"Price: $\"+str(ourmenu[name][\"price\"]))\n",
        "    print(\"\")\n",
        "    price += ourmenu[name][\"price\"]\n",
        "    calories += ourmenu[name][\"calories\"]\n",
        "print(\"Total calories: \"+str(calories))\n",
        "print(\"Total price: $\"+str(price))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_myUl-5whBmR"
      },
      "source": [
        "### HTML\n",
        "HTML is just XML with a specific schema for encoding webpages. So, we can use BeautifulSoup just the same here to get text content and hyperlinks, etcetera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im1D1kVhhBmR"
      },
      "outputs": [],
      "source": [
        "with open(\"index.html\", \"r\") as f:\n",
        "    webpage = f.read()\n",
        "print(webpage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Dd0RdIhBmR"
      },
      "source": [
        "Usually, content text lives in <\\p> tags in the <\\body>, and hyperlinks live in <\\a> tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LOaHUMnjhBmR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqHh6pj2hBmS"
      },
      "outputs": [],
      "source": [
        "websoup = BeautifulSoup(webpage, 'lxml')\n",
        "print(\"Here are any body paragraphs:\\n\")\n",
        "for paragraph in websoup.find_all(\"body\"):\n",
        "    print(\"Paragraph: \"+paragraph.find('p').text)\n",
        "    print(\"\")\n",
        "print(\"\\n\")\n",
        "print(\"Here are any Hyperlink display texts and URLs:\\n\")\n",
        "for hyperlink in websoup.find_all(\"a\"):\n",
        "    print(\"Hyperlink display text: \"+hyperlink.text)\n",
        "    print(\"Hyperlink URL: \"+hyperlink[\"href\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK0Fi7l8hBmT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp0DFDb1hBmT"
      },
      "source": [
        "### JSON\n",
        "JSON is probably the favorite associative array data type for most data scientists. In Pyton, it's very easy to load, and for its similarity to the Python dict object type can generally be navigated as such. Here, our json file is an example from YouTube's API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-ea6Sy3hBmU"
      },
      "outputs": [],
      "source": [
        "with open(\"youtube.json\", \"r\") as f:\n",
        "    video = json.loads(f.read())\n",
        "print(\"The data is actually one level into the schema:\\n\")\n",
        "print(video.keys())\n",
        "print(\"\")\n",
        "print(\"Here are the keys for the data on this video:\\n\")\n",
        "print(video[\"data\"].keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R3d5GFLhBmV"
      },
      "source": [
        "Within a list, the individual items are a good place to start exploring. Let's look at the first (only) item. Note That the values that we are printing out must be converted to strings. This is actually awesome, because it means that the json format implicitly encodes the object types, even in a text serialization (unlike XML). This is a real advantage for convenience in working with data&mdash;you don't necessarily have to cast types!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPBcQ2A6hBmV"
      },
      "outputs": [],
      "source": [
        "for key in video[\"data\"][\"items\"][0]:\n",
        "    print(key+\": \"+str(video[\"data\"][\"items\"][0][key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGtLvXi9hBmW"
      },
      "source": [
        "Creating your own json files is also quite easy because of the dict-json parallel. Let's take our converted restaurant menu and write out to a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2TTchc4WhBmW"
      },
      "outputs": [],
      "source": [
        "with open(\"simple.json\", \"w\") as f:\n",
        "    f.write(json.dumps(ourmenu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIvZ0YOfhBmW"
      },
      "source": [
        "The really cool thing about writing out the menu to json format (as we did) is that the json (unlike XML) format will carry forward the object tupes in the file. So, just as our YouTube data came in as ints and floats, the type changes that we made to the menu will be preserved in the output format!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "innuZ1RgjLlR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}